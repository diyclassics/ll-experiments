{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some spec work done 12/21/18 following this tweet:\n",
    "# https://twitter.com/MagisterConway/status/1075937446129471488\n",
    "# Hasn't been reviewed yet. Tweet corrections, etc. to @diyclassics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from cltk.corpus.latin import latinlibrary\n",
    "from cltk.tokenize.sentence import TokenizeSentence\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "from cltk.lemmatize.latin.backoff import BackoffLatinLemmatizer\n",
    "from cltk.stem.latin.j_v import JVReplacer\n",
    "from cltk.utils.file_operations import open_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training sentences\n",
    "\n",
    "rel_path = os.path.join('~/cltk_data/latin/model/latin_models_cltk/lemmata/backoff')\n",
    "path = os.path.expanduser(rel_path)\n",
    "\n",
    "# Check for presence of latin_pos_lemmatized_sents\n",
    "file = 'latin_pos_lemmatized_sents.pickle'      \n",
    "\n",
    "latin_pos_lemmatized_sents_path = os.path.join(path, file)\n",
    "if os.path.isfile(latin_pos_lemmatized_sents_path):\n",
    "    latin_pos_lemmatized_sents = open_pickle(latin_pos_lemmatized_sents_path)\n",
    "else:\n",
    "    latin_pos_lemmatized_sents = []\n",
    "    print('The file %s is not available in cltk_data' % file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CLTK tools\n",
    "\n",
    "word_tokenizer = WordTokenizer('latin')\n",
    "sent_tokenizer = TokenizeSentence('latin')\n",
    "lemmatizer = BackoffLatinLemmatizer(latin_pos_lemmatized_sents)\n",
    "replacer = JVReplacer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ovid/ovid.met1.txt', 'ovid/ovid.met2.txt', 'ovid/ovid.met3.txt', 'ovid/ovid.met4.txt', 'ovid/ovid.met5.txt', 'ovid/ovid.met6.txt', 'ovid/ovid.met7.txt', 'ovid/ovid.met8.txt', 'ovid/ovid.met9.txt', 'ovid/ovid.met10.txt', 'ovid/ovid.met11.txt', 'ovid/ovid.met12.txt', 'ovid/ovid.met13.txt', 'ovid/ovid.met14.txt', 'ovid/ovid.met15.txt']\n"
     ]
    }
   ],
   "source": [
    "met_files = [file for file in latinlibrary.fileids() if 'ovid.met' in file]\n",
    "met_order = [int(\" \".join(re.findall(r'\\d+', item))) for item in met_files]\n",
    "met_files = [x for _, x in sorted(zip(met_order, met_files))]\n",
    "print(met_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw text of Metamorphoses\n",
    "\n",
    "met_raw = latinlibrary.raw(met_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing script for the Latin Library\n",
    "\n",
    "def preprocess(text):    \n",
    "    \n",
    "    remove_list = [\n",
    "        r'Ovid: Metamorph*oses .+',\n",
    "        r'P. OVIDI NASONIS METAMORPHOSEN LIBER .+',\n",
    "        r'\\bOvid\\b',\n",
    "        r'The Latin Library',\n",
    "        r'The Classics Page',\n",
    "    ]\n",
    "    \n",
    "    for pattern in remove_list:\n",
    "        text = re.sub(pattern, '', text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text= re.sub(r'&lt;','<',text)\n",
    "    text= re.sub(r'&gt;','>',text)    \n",
    "\n",
    "    punctuation = string.punctuation\n",
    "    #punctuation += \"\\\"#$%&\\'()*+,-/:;<=>@[\\]^_`{|}~\"\n",
    "    translator = str.maketrans({key: \" \" for key in punctuation})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    text = replacer.replace(text)\n",
    "    \n",
    "    text = re.sub('[ ]+',' ', text) # Remove double spaces\n",
    "    text = re.sub('\\s+\\n+\\s+','\\n', text) # Remove double lines and trim spaces around new lines\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ovid: Metamorposes I\\r\\n\\t\\t \\r\\n\\r\\n\\t\\t \\r\\n\\t\\t \\r\\n\\t \\r\\n\\t\\r\\n \\r\\n\\r\\n P. OVIDI NASONIS METAMORPHOSEN LIBER PRIMVS\\r\\n \\r\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "met_raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in noua fert animus mutatas dicere formas \r\n",
      "corpora di coeptis nam uos mutastis et illas \r\n",
      "adspirate\n"
     ]
    }
   ],
   "source": [
    "# Preprocess Latin Library text\n",
    "\n",
    "met_pp = preprocess(met_raw)\n",
    "print(met_pp[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'noua', 'fert', 'animus', 'mutatas', 'dicere', 'formas', 'corpora', 'di', 'coeptis', 'nam', 'uos', 'mutastis', 'et', 'illas', 'adspirate', 'meis', 'prima', '-que', 'ab', 'origine', 'mundi', 'ad', 'mea', 'perpetuum', 'deducite', 'tempora', 'carmen', 'ante', 'mare', 'et', 'terras', 'et', 'quod', 'tegit', 'omnia', 'caelum', 'unus', 'erat', 'toto', 'naturae', 'uultus', 'in', 'orbe', 'quem', 'dixere', 'chaos', 'rudis', 'indigesta', '-que']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Latin Library text\n",
    "\n",
    "met_tokens = word_tokenizer.tokenize(met_pp)\n",
    "print(met_tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total token counts\n",
    "\n",
    "met_tokens_len = len(met_tokens)\n",
    "met_tokens_set_len = len(set(met_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in Metamorphoses: 82834\n",
      "Number of unique tokens in Metamorphoses: 18382\n"
     ]
    }
   ],
   "source": [
    "# Print top 10 token counts\n",
    "\n",
    "print('Number of tokens in Metamorphoses:', met_tokens_len)\n",
    "print('Number of unique tokens in Metamorphoses:', met_tokens_set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 tokens in Metamorphoses:\n",
      "\n",
      "       TOKEN       COUNT       Type-Tok %  RUNNING %   \n",
      "    1. -que        4383        5.29%       5.29%       \n",
      "    2. et          2131        2.57%       7.86%       \n",
      "    3. in          1164        1.41%       9.27%       \n",
      "    4. est         987         1.19%       10.46%      \n",
      "    5. nec         629         0.76%       11.22%      \n",
      "    6. non         588         0.71%       11.93%      \n",
      "    7. cum         462         0.56%       12.49%      \n",
      "    8. ut          379         0.46%       12.95%      \n",
      "    9. per         331         0.4%        13.34%      \n",
      "   10. -ne         319         0.39%       13.73%      \n",
      "   11. quae        297         0.36%       14.09%      \n",
      "   12. sed         292         0.35%       14.44%      \n",
      "   13. tamen       290         0.35%       14.79%      \n",
      "   14. mihi        275         0.33%       15.12%      \n",
      "   15. ad          274         0.33%       15.45%      \n",
      "   16. quoque      274         0.33%       15.78%      \n",
      "   17. quod        270         0.33%       16.11%      \n",
      "   18. si          251         0.3%        16.41%      \n",
      "   19. erat        244         0.29%       16.71%      \n",
      "   20. me          222         0.27%       16.98%      \n",
      "   21. iam         221         0.27%       17.24%      \n",
      "   22. illa        221         0.27%       17.51%      \n",
      "   23. ille        212         0.26%       17.77%      \n",
      "   24. quam        210         0.25%       18.02%      \n",
      "   25. qui         206         0.25%       18.27%      \n"
     ]
    }
   ],
   "source": [
    "# Build counter of top token counts\n",
    "\n",
    "met_tokens_counter = Counter(met_tokens)\n",
    "met_tokens_mc = met_tokens_counter.most_common(10000)\n",
    "\n",
    "running = 0\n",
    "\n",
    "print('Top 25 tokens in Metamorphoses:\\n')\n",
    "print(\"{number:>5}  {token:<12}{count:<12}{percent:<12}{running:<12}\".format(number=\"\", token=\"TOKEN\", count=\"COUNT\", percent=\"Type-Tok %\", running = \"RUNNING %\"))\n",
    "for i, pair in enumerate(met_tokens_mc[:25]):\n",
    "    running += pair[1]\n",
    "    print(\"{number:>5}. {token:<12}{count:<12}{percent:<12}{running:<12}\".format(number=i+1, token=pair[0], count=pair[1], percent=str(round(pair[1] / len(met_tokens)*100, 2))+\"%\", running = str(round(running / len(met_tokens)*100, 2))+\"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/met_counts/met_tokens.txt\", 'w') as f:\n",
    "    for k,v in  met_tokens_counter.most_common():\n",
    "        f.write( \"{} {}\\n\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('in', 'in'), ('noua', 'nouus'), ('fert', 'fero'), ('animus', 'animus'), ('mutatas', 'muto'), ('dicere', 'dico'), ('formas', 'forma'), ('corpora', 'corpus'), ('di', 'deus'), ('coeptis', 'coepio'), ('nam', 'nam'), ('uos', 'tu'), ('mutastis', 'muto'), ('et', 'et'), ('illas', 'ille'), ('adspirate', 'adspiro'), ('meis', 'meus'), ('prima', 'primus'), ('-que', '-que'), ('ab', 'ab'), ('origine', 'origo'), ('mundi', 'mundus'), ('ad', 'ad'), ('mea', 'meus'), ('perpetuum', 'perpetuus'), ('deducite', 'deduco'), ('tempora', 'tempus'), ('carmen', 'carmen'), ('ante', 'ante'), ('mare', 'mare'), ('et', 'et'), ('terras', 'terra'), ('et', 'et'), ('quod', 'qui'), ('tegit', 'tego'), ('omnia', 'omnis'), ('caelum', 'caelum'), ('unus', 'unus'), ('erat', 'sum'), ('toto', 'totus'), ('naturae', 'natura'), ('uultus', 'uultus'), ('in', 'in'), ('orbe', 'orbis'), ('quem', 'qui'), ('dixere', 'dico'), ('chaos', 'chaos'), ('rudis', 'rudis'), ('indigesta', 'indigestus'), ('-que', '-que'), ('moles', 'moles'), ('nec', 'neque'), ('quicquam', 'quisquam'), ('nisi', 'nisi'), ('pondus', 'pondus'), ('iners', 'iners'), ('congesta', 'congero'), ('-que', '-que'), ('eodem', 'idem'), ('non', 'non'), ('bene', 'bene'), ('iunctarum', 'iungo'), ('discordia', 'discordia'), ('semina', 'semen'), ('rerum', 'res'), ('nullus', 'nullus'), ('adhuc', 'adhuc'), ('mundo', 'mundus'), ('praebebat', 'praebeo'), ('lumina', 'lumen'), ('titan', 'titan'), ('nec', 'neque'), ('noua', 'nouus'), ('crescendo', 'cresco'), ('reparabat', 'reparo'), ('cornua', 'cornu'), ('phoebe', 'phoebus'), ('nec', 'neque'), ('circumfuso', 'circumfundo'), ('pendebat', 'pendo'), ('in', 'in'), ('aere', 'aer'), ('tellus', 'tellus'), ('ponderibus', 'pondus'), ('librata', 'libro'), ('suis', 'suus'), ('nec', 'neque'), ('bracchia', 'bracchium'), ('longo', 'longus'), ('margine', 'margo'), ('terrarum', 'terra'), ('porrexerat', 'porrigo'), ('amphitrite', 'amphitrite'), ('ut', 'ut'), ('-que', '-que'), ('erat', 'sum'), ('et', 'et'), ('tellus', 'tellus'), ('illic', 'illic'), ('et', 'et')]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize Latin Library text\n",
    "\n",
    "met_lemma_pairs = lemmatizer.lemmatize(met_tokens)\n",
    "print(met_lemma_pairs[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total lemma counts\n",
    "\n",
    "met_lemmas = [lemma[1] for lemma in met_lemma_pairs]\n",
    "met_lemmas_set_len = len(set(met_lemmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in Metamorphoses: 82834\n",
      "Number of unique tokens in Metamorphoses: 18382\n",
      "Number of unique lemmas in Metamorphoses: 7772\n"
     ]
    }
   ],
   "source": [
    "# Print top 10 token counts\n",
    "\n",
    "print('Number of tokens in Metamorphoses:', met_tokens_len)\n",
    "print('Number of unique tokens in Metamorphoses:', met_tokens_set_len)\n",
    "print('Number of unique lemmas in Metamorphoses:', met_lemmas_set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 lemmas in Metamorphoses:\n",
      "\n",
      "       LEMMA       COUNT       TYPE-LEM %  RUNNING %   \n",
      "    1. -que        4385        5.29%       5.29%       \n",
      "    2. sum         2166        2.61%       7.91%       \n",
      "    3. et          2131        2.57%       10.48%      \n",
      "    4. qui         1276        1.54%       12.02%      \n",
      "    5. in          1164        1.41%       13.43%      \n",
      "    6. ille        784         0.95%       14.37%      \n",
      "    7. hic         773         0.93%       15.31%      \n",
      "    8. neque       729         0.88%       16.19%      \n",
      "    9. ego         608         0.73%       16.92%      \n",
      "   10. non         588         0.71%       17.63%      \n",
      "   11. tu          507         0.61%       18.24%      \n",
      "   12. suus        472         0.57%       18.81%      \n",
      "   13. cum2        462         0.56%       19.37%      \n",
      "   14. uideo       427         0.52%       19.89%      \n",
      "   15. do          403         0.49%       20.37%      \n",
      "   16. ut          379         0.46%       20.83%      \n",
      "   17. dico        364         0.44%       21.27%      \n",
      "   18. per         331         0.4%        21.67%      \n",
      "   19. ab          320         0.39%       22.05%      \n",
      "   20. -ne         319         0.39%       22.44%      \n",
      "   21. possum      311         0.38%       22.82%      \n",
      "   22. fero        301         0.36%       23.18%      \n",
      "   23. facio       295         0.36%       23.54%      \n",
      "   24. sed         292         0.35%       23.89%      \n",
      "   25. tamen       290         0.35%       24.24%      \n"
     ]
    }
   ],
   "source": [
    "# Build counter of top lemma counts\n",
    "\n",
    "met_lemmas_counter = Counter(met_lemmas)\n",
    "met_lemmas_mc = met_lemmas_counter.most_common(10000)\n",
    "\n",
    "#print('Top 10 lemmas in Metamorphoses:\\n')\n",
    "#for i, pair in enumerate(met_lemmas_mc[:10]):\n",
    "#    print(\"{number}. {lemma}\\t\\t{count}\\t\\t{percent}%\".format(number=i+1, lemma=pair[0], count=pair[1], percent=round(pair[1] / len(met_tokens)*100, 2)))\n",
    "\n",
    "running = 0\n",
    "\n",
    "print('Top 25 lemmas in Metamorphoses:\\n')\n",
    "print(\"{number:>5}  {lemma:<12}{count:<12}{percent:<12}{running:<12}\".format(number=\"\", lemma=\"LEMMA\", count=\"COUNT\", percent=\"TYPE-LEM %\", running = \"RUNNING %\"))\n",
    "for i, pair in enumerate(met_lemmas_mc[:25]):\n",
    "    running += pair[1]\n",
    "    print(\"{number:>5}. {lemma:<12}{count:<12}{percent:<12}{running:<12}\".format(number=i+1, lemma=pair[0], count=pair[1], percent=str(round(pair[1] / len(met_tokens)*100, 2))+\"%\", running = str(round(running / len(met_tokens)*100, 2))+\"%\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/met_counts/met_lemmas.txt\", 'w') as f:\n",
    "    for k,v in  met_lemmas_counter.most_common():\n",
    "        f.write( \"{} {}\\n\".format(k,v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
